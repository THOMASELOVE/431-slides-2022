---
title: "431 Class 05"
author: "Thomas E. Love, Ph.D."
date: "2022-09-13"
format:
  revealjs: 
    theme: simple
    self-contained: true
    slide-number: true
    preview-links: auto
    logo: 431-class-foot2.png
    footer: "431 Class 05 | 2022-09-13 | https://thomaselove.github.io/431-2022/"
---

## Today's Agenda

- Setting up the `dm431` data
  - Looking closely at `age` and at systolic blood pressure

> Systolic blood pressure, the top number, measures the force the heart exerts on the walls of the arteries each time it beats. Diastolic blood pressure, the bottom number, measures the force the heart exerts on the walls of the arteries in between beats. (Mayo Clinic)

::: aside
Version `r Sys.time()`
:::

## Today's R Packages

```{r}
#| message: false
#| echo: true

library(janitor)
library(naniar) # although today's data are complete
library(patchwork)
library(tidyverse) # always load tidyverse last

theme_set(theme_light()) # other TEL option: theme_bw()
```

- Use `{r, message = FALSE}` in the code chunk header to silence messages about conflicts between R packages. 

## Code Chunk Header?

![](c05/images/code_chunk_header.png)

## Without `message = FALSE`?

```
Attaching package: ‘janitor’
The following objects are masked from ‘package:stats’: chisq.test, fisher.test

Registered S3 methods overwritten by 'dbplyr': 
  method         from
  print.tbl_lazy     
  print.tbl_sql      
── Attaching packages ─────────────────────────── tidyverse 1.3.2 ──
✔ tibble  3.1.8     ✔ purrr   0.3.4   ✔ tidyr   1.2.0     ✔ stringr 1.4.1
✔ readr   2.1.2     ✔ forcats 0.5.2─
─ Conflicts ──── ────────────────────────── tidyverse_conflicts() ──
✖ tidyr::expand() masks Matrix::expand()
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()
✖ tidyr::pack()   masks Matrix::pack()
✖ tidyr::unpack() masks Matrix::unpack()
```

## Ingesting Today's Data

```{r}
#| echo: true

dm431 <- read_csv("c05/data/dm_431.csv", show_col_types = FALSE)
```

- This is a (simulated) sample of 431 women with diabetes.
- Note the use of `read_csv` instead of `read.csv` here.
    - Can also run this without `show_col_types = FALSE` and you'll get a message (see next slide.)
    - Could instead silence message with <br /> `{r, message = FALSE}` in the code chunk header.

## Without `show_col_types = FALSE`

```

Rows: 431 Columns: 17

── Column specification ───────────────────────────────────────────────────────

Delimiter: ","

chr  (7): CLASS5_ID, INSURANCE, TOBACCO, RACE_ETHNICITY, SEX, COUNTY, SUBJECT
dbl (10): AGE, N_INCOME, HT, WT, SBP, DBP, A1C, LDL, STATIN, EYE_EXAM

ℹ Use `spec()` to retrieve the full column specification for this data.
ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

```

## A First Look at the tibble

```{r}
#| echo: true

dm431
```

## `dm431` variable names

```{r}
#| echo: true

names(dm431)
```

## First and last few subjects

```{r}
#| echo: true

head(dm431, 3)
tail(dm431, 2)  
```


## `dm431` glimpse (first few values)

```{r}
#| echo: true

glimpse(dm431)
```



## What would improve our data ingest?

- Clean up the variable names so that they are lower case (and, if they had any spaces or other problematic characters, replace those with underscores while also de-duplicating)
- Convert the categorical variables like `insurance` we might wind up analyzing from characters to factors
- Keep the `class5_id` variable (subject codes) as a character variable

## Re-ingesting Today's Data

```{r}
#| echo: true

dm431 <- read_csv("c05/data/dm_431.csv", show_col_types = FALSE) |>
  clean_names() |>
  mutate(across(where(is.character), as_factor)) |>
  mutate(class5_id = as.character(class5_id))
```

- `clean_names()` comes from the janitor package.
- The `across(where())` syntax tells R to change everything that gives a TRUE response to “is this a character variable?” into a factor variable.
- We want `class5_id` to be a character so we don't accidentally analyze it.

## The `dm431` data, version 2

```{r}
#| echo: true

dm431
```

## What is in `dm431`?

Simulated data to match Better Health Partnership specs. 

- This sample includes 431 female adults living with diabetes in Cuyahoga County who are within a certain age range, and who have complete data on all of the variables listed in this codebook.

## `dm431` codebook (part 1)

Variable | Description
-------: | :--------------------------------------------
`class5_id` | subject code (S-001 through S-431)
`age` | subject's age, in years
`insurance` | primary insurance, 4 levels
`n_income` | neighborhood median income, in $
`ht` | height, in meters (2 decimal places)
`wt` | weight, in kilograms (2 decimal places)

## `dm431` codebook (part 2)

Variable | Description
-------: | :--------------------------------------------
`sbp` | most recent systolic blood pressure (mm Hg)
`dbp` | most recent diastolic blood pressure (mm Hg)
`a1c` | most recent Hemoglobin A1c <br /> (%, with one decimal)
`ldl` | most recent LDL cholesterol level (mg/dl)
`tobacco` | most recent tobacco status, 3 levels
`statin` | 1 = prescribed a statin in past 12m, else 0

## `dm431` codebook (part 3)

Variable | Description
-------: | :--------------------------------------------
`eye_exam` | 1 = diabetic eye exam in past 12m, else 0
`race_ethnicity` | race/ethnicity category, 3 levels
`sex` | all subjects turn out to be Female
`county` | all subjects live in Cuyahoga County

- Again, these are 431 female adults living with diabetes in Cuyahoga County within a certain age range, with complete data on all variables in this codebook.

## New `dm431` variable structure

```{r}
#| echo: true

str(dm431)
```


## Checking for missingness

```{r}
#| echo: true

miss_case_table(dm431)
```

Can also use other functions from the `naniar` package to understand and cope with missing values:

- `miss_var_summary()` and `miss_var_table()`
- Next slide shows `gg_miss_var()` result
  - Note: warning silenced by `{r, warning = FALSE}` in chunk header.

## Plot of missingness in `dm431` tibble

```{r}
#| echo: true
#| warning: false

gg_miss_var(dm431)
```

## How old are these women?

- We want to describe the **center**, **spread** (dispersion) and **shape** (symmetry, outliers) of these 431 ages. 
- How might these summaries help?

```{r}
#| echo: true
#| message: false

dm431 |> select(age) |> summary()
```

- What is the age range of these women?

## More numerical summaries?

```{r}
#| echo: true

mosaic::favstats(~ age, data = dm431)
```

- Five-number summary of quantiles: <br /> `min`, `Q1`, `median`, `Q3` and `max`
- Mean and standard deviation (`sd`) of the ages
- Sample size (non-missing) and # of missing values

Can you envision the distribution of these ages?

## Raw Dot Plot of `dm431` Ages

```{r}
#| echo: true
ggplot(data = dm431, aes(x = age)) + 
  geom_dotplot(binwidth = 1) 
```

## Improved Dot Plot of `dm431` Ages

```{r}
#| echo: true
#| code-line-numbers: "2|3|"
ggplot(data = dm431, aes(x = age)) + 
  geom_dotplot(binwidth = 1, dotsize = 0.5, col = "royalblue") +
  scale_y_continuous(NULL, breaks = NULL)
```

## Using `psych::describe()`


```{r}
#| echo: true

psych::describe(dm431$age)
```

- What's new here?
  - `trimmed` = mean of middle 80% of data
  - `mad` = median absolute deviation (measures spread)
  - `se` = standard error of the mean $= {sd} / {\sqrt{n}}$
  - `skew` and `kurtosis` not so important today

## Using `Hmisc::describe()`

```{r}
#| echo: true

dm431 |> select(age) |> Hmisc::describe()
```

- What's new here?
  - `distinct`, `Info`, `Gmd`

## New `Hmisc::describe` elements

- `Hmisc::describe` treats a numeric variable as discrete if it has 10 or fewer distinct values
- `Info` is related to how "continuous" the variable is - it's a relative measure of the available information that is reduced below 1 by ties or non-distinct values
- `Gmd` = Gini's mean difference measures dispersion (spread). It is the mean absolute difference between any pairs of the 431 observations. Rhymes with "Mini."

---

![](c05/images/continuous_discrete.png)

# Plotting the `sbp` data to learn about center, spread, outliers and shape

## Systolic BP values from `dm431` (dotplot)

```{r}
#| echo: true

ggplot(data = dm431, aes(x = sbp)) +
  geom_dotplot(binwidth = 1) +
  labs(title = "431 SBP values for women with diabetes")
```

## Histogram of `dm431` Systolic BP

```{r}
#| echo: true

ggplot(data = dm431, aes(x = sbp)) +
  geom_histogram(binwidth = 5, fill = "royalblue", col = "gold") +
  labs(title = "431 SBP values for women with diabetes")
```

## Number of Bins in a Histogram

```{r}
p1 <- ggplot(data = dm431, aes(x = sbp)) +
  geom_histogram(bins = 5, fill = "seagreen",
                 col = "white") +
  labs(title = "Five bins")

p2 <- ggplot(data = dm431, aes(x = sbp)) +
  geom_histogram(bins = 10, fill = "tomato",
                 col = "white") +
  labs(title = "Ten bins")

p3 <- ggplot(data = dm431, aes(x = sbp)) +
  geom_histogram(bins = 15, fill = "salmon",
                 col = "white") +
  labs(title = "Fifteen bins")

p4 <- ggplot(data = dm431, aes(x = sbp)) +
  geom_histogram(bins = 20, fill = "slateblue",
                 col = "white") +
  labs(title = "Twenty bins")

(p1 + p2) / (p3 + p4) +
  plot_annotation(title = "431 SBP values for women with diabetes")
```

## "Pseudo-Code" for previous slide

```{r}
#| echo: true
#| eval: false

p1 <- ggplot(data = dm431, aes(x = sbp)) +
  geom_histogram(bins = 5, fill = "seagreen",
                 col = "white") +
  labs(title = "Five bins")

# omitting the code for plots p2-p4 in this slide, 
# use bins = 10, 15 and 20, respectively, and use
# tomato, salmon and slateblue for fill, respectively

(p1 + p2) / (p3 + p4) +
  plot_annotation(
    title = "431 SBP values for women with diabetes")
```

- You have the Quarto file for every set of slides in the README.

# Can we describe these data as being well-approximated by a Normal model?

## What is a Normal Model?

By a Normal model, we mean that the data are assumed to be the result of selecting at random from a probability distribution called the Normal (or Gaussian) distribution, which is characterized by a bell-shaped curve.

- The Normal model is defined by establishing the values of two parameters: the mean and the standard deviation.

## When is it helpful to assume our data follow a Normal model?

- When summarizing the data (especially if we want to interpret the mean and standard deviation)
- When creating inferences about populations from samples (as in a t test, or ANOVA)
- When creating regression models, it will often be important to make distributional assumptions about errors, for instance, that they follow a Normal model.

## Are our data "Normal enough"?

We evaluate whether a Normal model fits sufficiently well to our data on the basis of (in order of importance):

1. Graphs (**DTDP**) are the most important tool we have
    - There are several types of graphs designed to help us clearly identify potential problems with assuming Normality.

## Are our data "Normal enough"?

We evaluate whether a Normal model fits sufficiently well to our data on the basis of (in order of importance):

1. Graphs
2. Planned analyses after a Normal model decision is made
    - How serious the problems we see in graphs need to be before we worry about them changes substantially depending on how closely the later analyses we plan to do rely on the assumption of Normality.


## Are our data "Normal enough"?

We evaluate whether a Normal model fits sufficiently well to our data on the basis of (in order of importance):

1. Graphs
2. Planned analyses after decision is made
3. Numerical Summaries of the data
    - Definitely the least important even though they seem "easy-to-use" and "objective".

## Simulating Data from a Normal

Simulate a sample of 431 observations from a Normal model with mean and standard deviation equal to the mean and standard deviation of our `dm431` systolic BPs.

```{r}
#| echo: true

set.seed(2022)
sim_data <- tibble(
  sbp = rnorm(n = 431, mean = mean(dm431$sbp), sd = sd(dm431$sbp)))
```

## Simulated Sample vs. 431 Data

```{r}
#| echo: true
#| output-location: slide

p1 <- ggplot(data = dm431, aes(x = sbp)) +
  geom_dotplot(binwidth = 1, col = "navy") +
  labs(title = "431 SBP values for women with diabetes")

p2 <- ggplot(data = sim_data, aes(x = sbp)) +
  geom_dotplot(binwidth = 1, col = "deeppink") +
  labs(title = "431 Simulated SBP values")

p1 / p2
```

## Putting the plots together...

![](c05/images/patchwork_1.jpg)

## Comparing Histograms

```{r}
#| echo: true
#| output-location: slide

p1 <- ggplot(data = dm431, aes(x = sbp)) + 
  geom_histogram(binwidth = 5, fill = "navy", col = "gold") +
  scale_x_continuous(limits = c(70, 200), 
                     breaks = c(80, 100, 120, 140, 160, 180)) +
  labs(title = "431 Observed SBP values from dm431 (mean = 128.8, sd = 16.3)")

p2 <- ggplot(sim_data, aes(x = sbp)) +
  geom_histogram(binwidth = 5, fill = "deeppink", col = "black") +
  scale_x_continuous(limits = c(70, 200), 
                     breaks = c(80, 100, 120, 140, 160, 180)) +
  labs(title = "431 Simulated Values from Normal model with same mean and SD")

p1 / p2
```

## Graphs are our most important tool!

![](c05/images/not_normal.png)

## Rescale `dm431` SBP histogram as density

Suppose we want to rescale the histogram counts so that the bar areas integrate to 1. 

- This will let us overlay a Normal density onto the results.

```{r}
#| echo: true
#| output-location: slide

ggplot(dm431, aes(x = sbp)) +
  geom_histogram(aes(y = stat(density)), bins = 20, 
                 fill = "royalblue", col = "white")
```

## Density, with superimposed Normal

Now we can draw a Normal density curve on top of the rescaled histogram.

```{r}
#| echo: true
#| output-location: slide

ggplot(dm431, aes(x = sbp)) +
  geom_histogram(aes(y = stat(density)), bins = 20, 
                 fill = "royalblue", col = "white") +
  stat_function(fun = dnorm, 
                args = list(mean = mean(dm431$sbp), 
                            sd = sd(dm431$sbp)),
                col = "red", lwd = 1.5) +
  labs(title = "SBP density, with Normal model superimposed")
```

## Violin and Boxplot for `dm431` SBP

```{r}
#| echo: true
#| output-location: slide

ggplot(dm431, aes(x = "", y = sbp)) + 
  geom_violin(fill = "lemonchiffon") + 
  geom_boxplot(width = 0.3, fill = "royalblue", 
               outlier.size = 3, 
               outlier.color = "royalblue") + 
  coord_flip() + 
  labs(x = "dm431 sample")
```

## Observed vs. Simulated Systolic BPs

```{r}
#| echo: true
#| output-location: slide

p1 <- ggplot(dm431, aes(x = "", y = sbp)) + 
  geom_violin(fill = "lemonchiffon") + 
  geom_boxplot(width = 0.3, fill = "royalblue", 
               outlier.size = 3, 
               outlier.color = "royalblue") + 
  lims(y = c(70, 200)) +
  coord_flip() + 
  labs(x = "dm431 sample",
       title = "Observed SBP values")

p2 <- ggplot(sim_data, aes(x = "", y = sbp)) + 
  geom_violin(fill = "cornsilk") + 
  geom_boxplot(width = 0.3, fill = "deeppink", 
               outlier.size = 3, 
               outlier.color = "deeppink") + 
  lims(y = c(70, 200)) +
  coord_flip() + 
  labs(x = "Simulated data",
       title = "Simulated using a Normal distribution")

p1 / p2
```

# Using Numerical Summaries to Assess Normality: A Good Idea?

## Comparing Numerical Summaries

```{r}
#| echo: true

mosaic::favstats(~ sbp, data = dm431) 
mosaic::favstats(~ sbp, data = sim_data)
```

What can we learn from these comparisons...

- about the center of the data?
- about the spread of the data?
- about the shape of the data?

## Does a Normal model fit well for my data?

The least important approach (even though it is seemingly the most objective) is the calculation of various numerical summaries.

Semi-useful summaries help us understand whether they match up well with the expectations of a normal model:

1. Assessing skewness with $skew_1$ (is the mean close to the median?)
2. Assessing coverage probabilities (do they match the Normal model?)

## Quantifying skew with $skew_1$

$$
skew_1 = \frac{mean - median}{standard \ deviation}
$$

### Interpreting $skew_1$ (for unimodal data)

- $skew_1 = 0$ if the mean and median are the same
- $skew_1 > 0.2$ indicates fairly substantial right skew
- $skew_1 < -0.2$ indicates fairly substantial left skew


## Measuring skew in `dm431` SBP?

```{r}
#| echo: true
mosaic::favstats(~ sbp, data = dm431)
```

```{r}
#| echo: true
dm431 |> 
  summarize(skew1 = (mean(sbp) - median(sbp))/sd(sbp))
```

What does this suggest?

## For any data set...

Remember that, regardless of the distribution of the data:

- Half of the data will fall below the median, and half above it.
- Half of the data will fall in the Interquartile Range (IQR).

## Empirical Rule for a Normal Model

If the data followed a Normal distribution, perfectly, then about:

- 68% of the data would fall within 1 standard deviation of the mean
- 95% of the data would fall within 2 standard deviations of the mean
- 99.7% of the data would fall within 3 standard deviations of the mean

## SBPs within 1 SD of the mean?

```{r}
#| echo: true
dm431 |>
  count(sbp > mean(sbp) - sd(sbp), 
        sbp < mean(sbp) + sd(sbp)) 
```

- Note that 306/431 = 0.71, approximately.
- How does this compare to the expectation under a Normal model? 

## SBP and $\bar{x} \pm 2 sd$ rule?

```{r}
#| echo: true
dm431 |>
  count(sbp > mean(sbp) - 2*sd(sbp), 
        sbp < mean(sbp) + 2*sd(sbp)) 
```

- Note that 411/431 = 0.95, approximately.
- How does this compare to the expectation under a Normal model? 

# Should we use hypothesis tests to assess Normality?

## Hypothesis Testing to assess Normality

Don't. Graphical approaches are **far** better than hypothesis tests...

```{r}
#| echo: true
shapiro.test(dm431$sbp)
```

The very small *p* value indicates that the test finds some indications **against** adopting a Normal model for these data. 

- Exciting, huh? But not actually all that useful, alas.

## Why not test for Normality? (1)

There are multiple hypothesis testing schemes (Kolmogorov-Smirnov, etc.) and each looks for one specific violation of a Normality assumption. 

- None can capture the wide range of issues our brains can envision, and none by itself is great at its job.
- With any sort of reasonable sample size, the test is so poor at detecting non-normality compared to our eyes, that it finds problems we don't care about and ignores problems we do care about.

## Why not test for Normality? (2)

- And without a reasonable sample size, the test is essentially useless.

Whenever you *can* avoid hypothesis testing and instead actually plot the data, you should **plot the data**. 

Sometimes you can't plot (especially with really big data) but the test should be your very last resort.

## For next time...

- Please complete the **Minute Paper** by noon Wednesday. 
- Next time, we'll discuss several things, including...
  - Normal Q-Q plots
  - Building confidence intervals for numerical summaries of a single batch of quantitative data
  - Comparing distributions from two batches of quantitative data

## Session Information

```{r}
#| echo: true
sessionInfo()
```
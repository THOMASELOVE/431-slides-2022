---
title: "431 Class 09"
author: "Thomas E. Love, Ph.D."
date: "2022-09-27"
format:
  revealjs: 
    theme: simple
    self-contained: true
    slide-number: true
    preview-links: auto
    logo: 431-class-foot2.png
    footer: "431 Class 09 | 2022-09-27 | https://thomaselove.github.io/431-2022/"
---

## Today's Agenda

Details coming soon.

::: aside
Version `r Sys.time()`
:::

## Today's Setup

```{r}
#| echo: true

knitr::opts_chunk$set(comment=NA)
library(broom)
library(equatiomatic)        ## pull equations from regressions
library(ggrepel)             ## build useful labels in ggplot2
library(ggridges)            ## help with ridgeline plots
library(glue)                ## work with strings
library(janitor)
library(kableExtra)
library(naniar)
library(patchwork)
library(tidyverse)

theme_set(theme_bw())
```


## Today's Data

Today, we'll use an R data set (`.Rds`) to import the `dm1000` data.

```{r}
dm1000 <- read_rds("c09/data/dm_1000.Rds")
```

- This allows us to read in the data just as they were last saved in R, including "factoring" and handling of missing data, etc. The function `readRDS()` also works but is a little slower.
- To write an R data set, we'll use `write_rds(datasetname, "locationoncomputer")`. The function `saveRDS()` would also work, in a similar way, but be a little slower.

# Comparing Multiple (more than 2) Batches of Data

## Stratify the subjects by primary `insurance`?

```{r}
#| echo: true
dm1000 |> count(insurance) |>
  mutate(pct = 100*n/sum(n)) |>
  kbl(digits = 1)
```

## Missingness?

```{r}
miss_var_summary(dm1000)
```



## Let's look at `n_income` (ignoring 28 NA)

```{r}
#| echo: true
#| warning: false
#| output-location: slide

p1 <- ggplot(dm1000, aes(sample = n_income)) +
  geom_qq(col = "slateblue") + 
  geom_qq_line(col = "magenta") + 
  theme(aspect.ratio = 1) + 
  labs(title = "Normal Q-Q plot: n_income")

p2 <- ggplot(dm1000, aes(x = n_income)) +
  geom_histogram(aes(y = stat(density)), 
                 bins = 20, fill = "slateblue", col = "cyan") +
  stat_function(fun = dnorm, 
                args = list(mean = mean(dm1000$n_income, na.rm = TRUE), 
                            sd = sd(dm1000$n_income, na.rm = TRUE)),
                col = "magenta", lwd = 1.5) +
  labs(title = "Density Function: n_income")

p3 <- ggplot(dm1000, aes(x = n_income, y = "")) +
  geom_boxplot(fill = "slateblue", outlier.color = "slateblue") + 
  labs(title = "Boxplot: n_income", y = "")

p1 + (p2 / p3 + plot_layout(heights = c(4,1)))
```

## `n_income` by insurance: Boxplot?

```{r}
#| echo: true
#| warning: true
ggplot(dm1000, aes(x = insurance, y = n_income)) +
  geom_boxplot()
```


## Build a better boxplot?

```{r}
#| echo: true
#| output-location: slide

tempdat <- dm1000 |> filter(complete.cases(insurance, n_income))

ggplot(data = tempdat, aes(x = insurance, y = n_income/1000)) +
  geom_violin(aes(fill = insurance)) +
  geom_boxplot(width = 0.3, outlier.size = 2) +
  guides(fill = "none") +
  coord_flip() +
  scale_fill_viridis_d(alpha = 0.5) +
  labs(y = "Neighborhood Income (in $1000s)",
       x = "Primary Insurance Category",
       title = "dm1000 Income by Insurance Type")
```

## Faceted Histograms of `n_income` by `insurance`

```{r}
#| echo: true
#| warning: true
ggplot(data = dm1000, aes(x = n_income)) +
  geom_histogram(binwidth = 2500) +
  facet_wrap(~ insurance)
```

## Improving the Histograms

```{r}
#| echo: true
#| output-location: slide

tempdat <- dm1000 |> filter(complete.cases(insurance, n_income))

ggplot(data = tempdat, aes(x = n_income, fill = insurance)) +
  geom_histogram(binwidth = 2500, col = "navy") +
  scale_x_continuous(
    breaks = c(5000, 25000, 50000, 75000, 100000)) +
  guides(fill = "none") +
  facet_wrap(~ insurance) +
  labs(title = "Neighborhood Income, in $")
```

## Comparing Densities of `n_income` by `insurance`

```{r}
#| echo: true
#| output-location: slide

tempdat <- dm1000 |> filter(complete.cases(insurance, n_income))

ggplot(data = tempdat, aes(x = n_income, fill = insurance)) +
  geom_density() +
  scale_fill_viridis_d(alpha = 0.3)
```

## Using a Ridgeline Plot

```{r}
#| echo: true

tempdat <- dm1000 |> filter(complete.cases(insurance, n_income))
ggplot(data = tempdat, aes(x = n_income, y = insurance, 
                       fill = insurance)) +
  geom_density_ridges(alpha = 0.5) +
  labs(title = "Neighborhood Income, in $")
```

## Sample Summaries of `n_income`

```{r}
#| echo: true
mosaic::favstats(n_income ~ insurance, data = dm1000)
```


## Comparing the Means of `n_income`

```{r}
#| echo: true
m1 <- lm(n_income ~ insurance, data = dm1000)

tidy(m1) |> select(term, estimate) |> kbl(digits = 2)
```

- What is m1's estimated `n_income` for each of the insurance groups?

## `m1`: Estimated `n_income` for each insurance

```
n_income = 33150.74 + 7564.28 Commercial + 732.76 Medicare + 4724.00 Uninsured
```

Insurance | Estimated `n_income` 
--------: | --------: 
Commercial | 33150.74 + 7564.28 = 40715.02 
Medicare | 33150.74 + 732.76 = 33883.50
Uninsured | 33150.74 + 4724.00 = 37874.74
Medicaid | 33150.74

## `m1`: Estimated `n_income` for each insurance

```
n_income = 33150.74 + 7564.28 Commercial + 732.76 Medicare + 4724.00 Uninsured
```

Insurance | `m1` est. | Sample mean(`n_income`)
--------: | :--------: | :--------:
Commercial | 40715.0 | 40715.0
Medicare | 33883.5 | 33883.5
Uninsured | 37874.7 | 33874.7
Medicaid | 33150.7 | 33150.7

## Model `m1` coefficients

```{r}
#| echo: true
tidy(m1, conf.int = TRUE, conf.level = 0.95) |>
  select(term, estimate, conf.low, conf.high) |>
  kbl(digits = 2) |> kable_styling(font_size = 28)
```

- 95% CI for pop. mean `n_income` among adults with Medicaid is (31097, 35205)

## Model `m1` coefficients

```{r}
#| echo: true
tidy(m1, conf.int = TRUE, conf.level = 0.95) |>
  select(term, estimate, conf.low, conf.high) |>
  kbl(digits = 2) |> kable_styling(font_size = 28)
```

- 95% CI for Commercial - Medicaid is (4237, 10891)
- What about Medicare - Medicaid?
- Uninsured - Medicaid?

## Comparing `n_income` across `insurance` groups

```{r}
#| echo: true

mosaic::favstats(n_income ~ insurance, data = dm1000)
```

- Does a comparison of means make sense here?
- Would it give us the same conclusions as comparing medians?

## Replot on logarithmic (base 10) scale?

```{r}
#| echo: true
#| output-location: slide

tempdat <- dm1000 |> filter(complete.cases(insurance, n_income))

ggplot(data = tempdat, aes(x = insurance, y = n_income)) +
  geom_violin(aes(fill = insurance)) +
  geom_boxplot(width = 0.3, outlier.size = 2) +
  guides(fill = "none") +
  coord_flip() +
  scale_fill_viridis_d(alpha = 0.5) +
  scale_y_continuous(trans = "log10") +
  labs(y = "Neighborhood Income (in $, log10 scale)",
       x = "Primary Insurance Category",
       title = "dm1000 Income by Insurance Type")
```

## Does which logarithmic scale you pick matter?

```{r}
#| echo: true
#| output-location: slide

tempdat <- dm1000 |> filter(complete.cases(insurance, n_income))

p1 <- ggplot(data = tempdat, aes(x = insurance, y = n_income)) +
  geom_violin(aes(fill = insurance)) +
  geom_boxplot(width = 0.3, outlier.size = 2) +
  guides(fill = "none") +
  coord_flip() +
  scale_fill_viridis_d(alpha = 0.5) +
  scale_y_continuous(trans = "log") +
  labs(y = "Neighborhood Income (in $, log, base e scale)",
       x = "Primary Insurance Category",
       title = "Natural Log Scale")

p2 <- ggplot(data = tempdat, aes(x = insurance, y = n_income)) +
  geom_violin(aes(fill = insurance)) +
  geom_boxplot(width = 0.3, outlier.size = 2) +
  guides(fill = "none") +
  coord_flip() +
  scale_fill_viridis_d(alpha = 0.5) +
  scale_y_continuous(trans = "log10") +
  labs(y = "Neighborhood Income (in $, log10 scale)",
       x = "Primary Insurance Category",
       title = "Log (base 10) Scale")

p1 + p2
```

## Ridgeline Plot of Densities on Log Scale

```{r}
#| echo: true
#| output-location: slide

tempdat <- dm1000 |> filter(complete.cases(insurance, n_income))

ggplot(data = tempdat, aes(x = n_income, y = insurance, 
                       fill = insurance)) +
  geom_density_ridges(alpha = 0.5) +
  scale_x_continuous(trans = "log10") +
  labs(title = "Neighborhood Income, log10 scale")
```

# Working With Scatterplots

## ## Partitioning `dm1000` into two groups

Before we do anything else today, let's split the data in `dm1000` who have complete data on `sbp` and `dbp` into two groups:

- a model **development** or **training** sample (70% of rows)
- a model **evaluation** or **test** sample (the other 30%)

There are many ways to do this in R. Let's start by filtering out the observations with missing values of blood pressure.

```{r}
dm994 <- dm1000 |> filter(complete.cases(sbp, dbp)) %>%
  select(subject, sbp, dbp, insurance)

dm994 |> nrow()
n_distinct(dm994$subject)
```

OK. We have a unique `subject` value for each of the 994 rows.

## Now, let's build the partition.

Again, we want 70% of the sample in our training set, and the remaining 30% in our test set.

```{r}
set.seed(4312021) # for replicating the sampling later

dm_train <- dm994 |> sample_frac(0.7)
dm_test <- dm994 |> anti_join(dm_train, by = "subject")

nrow(dm_train); nrow(dm_test)
```

OK. Looks good!

# Can `dbp` predict `sbp`?

## Plotting `sbp` vs. `dbp` (training set)

```{r}
#| echo: true
#| output-location: slide

ggplot(data = dm_train, aes(x = dbp, y = sbp)) +
  geom_point() + 
  geom_smooth(method = "loess", col = "blue",
              se = FALSE, formula = y ~ x) +
  geom_smooth(method = "lm", col = "red",
              se = FALSE, formula = y ~ x) +
  geom_label(x = 120, y = 100, size = 5,
            label = glue('Pearson r = {round_half_up(
            cor(dm_train$sbp, dm_train$dbp),2)}.')) +
  geom_label_repel(data = dm_train %>% filter(dbp > 120),
                  aes(label = subject), fill = "yellow") +
  labs(title = "Positive Association of SBP and DBP",
       subtitle = "loess smooth in blue, OLS model in red",
       caption = 
         glue('{nrow(dm_train)} subjects from dm_train.'))
```

## Redo plot without point M-0862

- Note increased size and new color of point M-0862, use of geom_text_repel instead of geom_label_repel, adjusted caption.

```{r}
#| echo: true
#| output-location: slide

ggplot(data = dm_train, aes(x = dbp, y = sbp)) +
  geom_point() + 
  geom_smooth(data = dm_train %>% filter(dbp <= 120), 
              method = "loess", col = "blue",
              se = FALSE, formula = y ~ x) +
  geom_smooth(data = dm_train %>% filter(dbp <= 120), 
              method = "lm", col = "red",
              se = FALSE, formula = y ~ x) +
  geom_point(data = dm_train %>% filter(dbp > 120), 
             aes(col = "purple", size = 3)) +
  geom_text_repel(data = dm_train %>% filter(dbp > 120),
                  aes(label = subject)) +
  guides(color = "none", size = "none") +
  labs(title = "What happens if we drop M-0862?",
       subtitle = "Newly fit loess in blue, new OLS in red",
       caption = glue('{nrow(dm_train)-1} subjects.'))
```

## Modeling `sbp` using `dbp` (training set)

```{r}
m1_train <- lm(sbp ~ dbp, data = dm_train)

tidy(m1_train, conf.int = TRUE, conf.level = 0.90) %>% 
  select(term, estimate, conf.low, conf.high) %>% kable()

glance(m1_train) %>% select(nobs, r.squared) %>% kable()
```

## Summarizing the Training Fit

1. We can use `extract_eq()` from the `equatiomatic` package to present the equation from our model in a fairly attractive way, but we must use the code chunk header `{r, results = 'asis'}`.

```{r, results = 'asis'}
extract_eq(m1_train, use_coefs = TRUE, coef_digits = 3)
```

2. The `summary` function when applied to a linear model (`lm`) produces output that isn't organized in a way that allows up to plot or present it effectively outside of an R session.

```{r, eval = FALSE}
summary(m1_train)
```

A screenshot follows on the next page.

---

![](c09/images/m1_train_summary.png)

## Why I like `tidy()` and other `broom` functions

![](c09/images/broom_package.png)

https://github.com/allisonhorst/stats-illustrations

## Does R like this linear model?

```{r}
tidy(m1_train) %>% kable(digits = 3)
```

Yes. Wow. It **really** does. Look at those *p* values!

## How much of the variation in `sbp` does m1 capture?

The `glance` function can help us (again from `broom`.) 

```{r}
glance(m1_train) %>% 
  select(nobs, r.squared, p.value, sigma) %>% kable()
```

- `r.squared` = $R^2$, the proportion of variation in `sbp` accounted for by the model using `dbp`. 
  - indicates improvement over predicting mean(`sbp`) for everyone
- `p.value` = refers to a global F test 
  - indicates something about combination of $r^2$ and sample size
- `sigma` = residual standard error 

`glance` provides 9 additional summaries for a linear model.

# Calibrating Yourself on R-square

## Can you match each plot to its R-square?

```{r, echo = FALSE}
set.seed(4312020)

correxs <- tibble(x = seq(10.5,110, by = 0.5),
                  y1 = -0.01*x + rpois(200, lambda = 14),
                  y2 = 0.023*x + rpois(200, lambda = 16),
                  y3 = -0.049*x + rpois(200, lambda = 20),
                  y4 = 0.0504*x + rpois(200, lambda = 20),
                  y5 = -0.085*x + rpois(200, lambda = 18),
                  y6 = -0.095*x + rpois(200, lambda = 19),
                  y7 = 0.15*x + rpois(200, lambda = 20),
                  y8 = -0.185*x + rpois(200, lambda = 20),
                  y0 = rpois(200, lambda = 16),
                  y9 = 0.315*x + rpois(200, lambda = 19),
                  y10 = -0.435*x + rpois(200, lambda = 16),
                  y11 = 1.01*x + rpois(200, lambda = 17))
```

```{r, echo = FALSE}
p4a <- ggplot(correxs, aes(x = x, y = y4)) + 
  geom_point(col = "blue", pch = 1) + 
  geom_smooth(method = "lm", col = "red", formula = "y ~ x", se = FALSE) + 
  theme(aspect.ratio = 1) +
  labs(title = "C. R-square = ?", y = "", x = "")

p5a <- ggplot(correxs, aes(x = x, y = y5)) + 
  geom_point(col = "blue", pch = 1) + 
  geom_smooth(method = "lm", col = "red", formula = "y ~ x", se = FALSE) + 
  theme(aspect.ratio = 1) +
  labs(title = "E. R-square = ?", y = "", x = "")

p7a <- ggplot(correxs, aes(x = x, y = y7)) + 
  geom_point(col = "blue", pch = 1) + 
  geom_smooth(method = "lm", col = "red", formula = "y ~ x", se = FALSE) + 
  theme(aspect.ratio = 1) +
  labs(title = "D. R-square = ?", y = "", x = "")

p8a <- ggplot(correxs, aes(x = x, y = y8)) + 
  geom_point(col = "blue", pch = 1) + 
  geom_smooth(method = "lm", col = "red", formula = "y ~ x", se = FALSE) + 
  theme(aspect.ratio = 1) +
  labs(title = "B. R-square = ?", y = "", x = "")

p9a <- ggplot(correxs, aes(x = x, y = y9)) + 
  geom_point(col = "blue", pch = 1) + 
  geom_smooth(method = "lm", col = "red", formula = "y ~ x", se = FALSE) + 
  theme(aspect.ratio = 1) +
  labs(title = "A. R-square = ?", y = "", x = "")

p10a <- ggplot(correxs, aes(x = x, y = y10)) + 
  geom_point(col = "blue", pch = 1) + 
  geom_smooth(method = "lm", col = "red", formula = "y ~ x", se = FALSE) + 
  theme(aspect.ratio = 1) +
  labs(title = "F. R-sq = ?", y = "", x = "")

```

```{r, echo = FALSE}
(p9a + p8a + p4a) / (p7a + p5a + p10a)
```

- $R^2$ values shown include 0.16, 0.25, 0.49, 0.64, 0.81 and 0.91

## Gaining Insight into what R-square implies

```{r, echo = FALSE}
p4b <- ggplot(correxs, aes(x = x, y = y4)) + 
  geom_point(col = "blue", pch = 1) + 
  geom_smooth(method = "lm", col = "red", formula = "y ~ x", se = FALSE) + 
  theme(aspect.ratio = 1) +
  labs(title = "r = +0.4, R-sq = 0.16", y = "", x = "")

p5b <- ggplot(correxs, aes(x = x, y = y5)) + 
  geom_point(col = "blue", pch = 1) + 
  geom_smooth(method = "lm", col = "red", formula = "y ~ x", se = FALSE) + 
  theme(aspect.ratio = 1) +
  labs(title = "r = -0.5, R-sq = 0.25", y = "", x = "")

p7b <- ggplot(correxs, aes(x = x, y = y7)) + 
  geom_point(col = "blue", pch = 1) + 
  geom_smooth(method = "lm", col = "red", formula = "y ~ x", se = FALSE) + 
  theme(aspect.ratio = 1) +
  labs(title = "r = +0.7, R-sq = 0.49", y = "", x = "")

p8b <- ggplot(correxs, aes(x = x, y = y8)) + 
  geom_point(col = "blue", pch = 1) + 
  geom_smooth(method = "lm", col = "red", formula = "y ~ x", se = FALSE) + 
  theme(aspect.ratio = 1) +
  labs(title = "r = -0.8, R-sq = 0.64", y = "", x = "")

p9b <- ggplot(correxs, aes(x = x, y = y9)) + 
  geom_point(col = "blue", pch = 1) + 
  geom_smooth(method = "lm", col = "red", formula = "y ~ x", se = FALSE) + 
  theme(aspect.ratio = 1) +
  labs(title = "r = +0.9, R-sq = 0.81", y = "", x = "")

p10b <- ggplot(correxs, aes(x = x, y = y10)) + 
  geom_point(col = "blue", pch = 1) + 
  geom_smooth(method = "lm", col = "red", formula = "y ~ x", se = FALSE) + 
  theme(aspect.ratio = 1) +
  labs(title = "r = -0.95, R-sq = 0.905", y = "", x = "")

```

```{r, echo = FALSE}
(p9b + p8b + p4b) / (p7b + p5b + p10b)
```

# Obtaining Residuals and Fitted Values in the Training Sample

## Predict using `m1_train`: `sbp` = 80.68 + 0.70 `dbp`

Use `augment` (from `broom`) to capture fitted values and residuals for all of the data in the training sample.

```{r}
augment(m1_train, data = dm_train) %>%
  select(subject, sbp, dbp, .fitted, .resid) %>% 
  slice_min(., order_by = subject, n = 2) %>% kable(dig = 2)
```

- Subject M-0002 has an observed `sbp` of	151, and `dbp` of 77.
- Our `m1_train` model **fits** (predicts) M-0002's `sbp` to be 134.44, so that's a **residual** of 151 - 134.44 = 16.56 mm Hg. 
- Note that **residual** = **observed** - **fitted**.

## What must we assume for a regression model?

Briefly (for now), we assume that:

- the regression relationship is linear, rather than curved, and we can assess this by plotting the regression residuals (prediction errors) against the fitted values and looking to see if a curve emerges
- the regression residuals show similar variance across levels of the fitted values, and again we can get insight into this by plotting residuals vs. predicted values
- the regression residuals (prediction errors) are well described by a Normal model, and we can assess this with all of our usual visualizations to help decide on whether a Normal model is reasonable for a batch of data.

- We assess all of these issues (and others) with plots of the residuals. Let's start with the **Normality** assumption...

## Plot residuals from `m1_train`

```{r, echo = FALSE, message = FALSE}
m1_train_aug <- augment(m1_train, data = dm_train)

p1 <- ggplot(m1_train_aug, aes(sample = .resid)) +
  geom_qq(col = "seagreen") + geom_qq_line(col = "black") + 
  theme(aspect.ratio = 1) + 
  labs(title = "Normal Q-Q: 994 m1 Residuals")

p2 <- ggplot(m1_train_aug, aes(x = .resid)) +
  geom_histogram(aes(y = stat(density)), 
                 bins = 20, fill = "seagreen", col = "yellow") +
  stat_function(fun = dnorm, 
                args = list(mean = mean(m1_train_aug$.resid), 
                            sd = sd(m1_train_aug$.resid)),
                col = "black", lwd = 1.5) +
  labs(title = "Hist + Normal Density: m1 Residuals")

p3 <- ggplot(m1_train_aug, aes(x = .resid, y = "")) +
  geom_boxplot(fill = "seagreen", outlier.color = "seagreen") + 
  labs(title = "Boxplot: m1 Residuals", y = "")

p1 + (p2 / p3 + plot_layout(heights = c(4,1)))

mosaic::favstats(~ .resid, data = m1_train_aug) %>% kable(digits = 1)
```

## Plot Residuals vs. Predicted (Fitted) Values (code)

```{r, eval = FALSE}
m1_train_aug <- augment(m1_train, data = dm_train)

ggplot(m1_train_aug, aes(x = .fitted, y = .resid)) +
  geom_point() +
  geom_smooth(method = "lm", col = "red",
              formula = y ~ x, se = FALSE) + 
  geom_smooth(method = "loess", col = "blue",
              formula = y ~ x, se = FALSE) +
  labs(title = "m1_train: Residuals vs. Fitted Values", 
       x = "Fitted sbp values", y = "Residuals")
```

## m1_train: Residuals vs. Predicted (Fitted) Values

- We're looking to see if there is a substantial curve in the plot, or if the variability changes materially from left to right.
- What we want to see is a "fuzzy football" actually.

```{r, fig.height = 4, echo = FALSE}
m1_train_aug <- augment(m1_train, data = dm_train)

ggplot(m1_train_aug, aes(x = .fitted, y = .resid)) +
  geom_point() +
  geom_smooth(method = "lm", col = "red",
              formula = y ~ x, se = FALSE) + 
  geom_smooth(method = "loess", col = "blue",
              formula = y ~ x, se = FALSE) +
  labs(title = "m1_train: Residuals vs. Fitted Values", 
       x = "Fitted sbp values", y = "Residuals")
```

## This sort of fuzzy football...

![](c09/images/fuzzy_football.png)

# Making Predictions Out of Sample (into the Test Sample)

## Use model `m1_train` to predict SBP in `dm_test`

```{r}
m1_test_aug <- augment(m1_train, newdata = dm_test)

m1_test_aug %>% nrow()
```

- We have predictions from `m1_train` for the `r m1_test_aug %>% nrow()` subjects in `dm_test`.
- Remember we didn't use the `dm_test` data to build `m1_train`.

```{r}
m1_test_aug %>% 
  select(subject, sbp, dbp, .fitted, .resid) %>% 
  slice_min(., order_by = subject, n = 2) %>% kable(dig = 2)
```

## `dm_test` (n = 298): `m1_train` Prediction Errors

```{r, echo = FALSE}
p1 <- ggplot(m1_test_aug, aes(sample = .resid)) +
  geom_qq(col = "darkorchid") + geom_qq_line(col = "black") + 
  theme(aspect.ratio = 1) + 
  labs(title = "Normal Q-Q: 298 m1_train Errors")

p2 <- ggplot(m1_test_aug, aes(x = .resid)) +
  geom_histogram(aes(y = stat(density)), 
                 bins = 20, fill = "darkorchid", col = "green") +
  stat_function(fun = dnorm, 
                args = list(mean = mean(m1_test_aug$.resid), 
                            sd = sd(m1_test_aug$.resid)),
                col = "black", lwd = 1.5) +
  labs(title = "Hist + Normal Density: 298 m1_train Errors")

p3 <- ggplot(m1_test_aug, aes(x = .resid, y = "")) +
  geom_boxplot(fill = "darkorchid", outlier.color = "darkorchid") + 
  labs(title = "Boxplot: 298 m1_train Errors", y = "")

p1 + (p2 / p3 + plot_layout(heights = c(4,1)))

mosaic::favstats(~ .resid, data = m1_test_aug) %>% kable(digits = 1)
```

## Out-of-Sample (Test Set) Error Summaries (`m1`)

- Mean Absolute Prediction Error = `r round_half_up(mean(abs(m1_test_aug$.resid)),2)`
- Maximum Absolute Prediction Error = `r round_half_up(max(abs(m1_test_aug$.resid)),2)`
- (square Root of) Mean Squared Prediction Error (RMSPE) = `r round_half_up(sqrt(mean(m1_test_aug$.resid^2)),2)`

```{r}
mosaic::favstats(~ abs(.resid), data = m1_test_aug) %>%
  select(n, min, median, max, mean, sd) %>%
  kable(digits = 2)

sqrt(mean(m1_test_aug$.resid^2))
```

These statistics are most useful when we're comparing two models.

## Back to all 994 values. Does `m1_train` work well?

```{r, fig.height = 4.5}
ggplot(dm994, aes(x = dbp, y = sbp)) + 
  geom_point() + theme(aspect.ratio = 1) +
  geom_abline(intercept = 80.6799, slope = 0.6982, 
              col = "purple", lwd = 2.5, alpha = 0.5)
```

## Is this the only linear model R can fit to these data?

Nope.

```{r}
library(rstanarm)

m2_train <- stan_glm(sbp ~ dbp, data = dm_train)
```

## Bayesian fitted linear model for our sbp data

```{r}
print(m2_train)
```

## Is the Bayesian model (with default prior) very different from our `lm` in this situation?

```{r}
broom::tidy(m1_train) # fit with lm

broom.mixed::tidy(m2_train) # stan_glm with default priors
```

## Test Sample fits and residuals from Bayesian model

```{r}
m2_test_aug <- dm_test %>% select(subject, sbp, dbp) %>%
  mutate(.fitted = predict(m2_train, newdata = dm_test),
         .resid = sbp - .fitted)

m2_test_aug %>% 
  select(subject, sbp, dbp, .fitted, .resid) %>% 
  slice_min(., order_by = subject, n = 2) %>% kable(dig = 2)
```

## Out-of-Sample (Test Set) Error Summaries (`m2`)

```{r}
mosaic::favstats(~ abs(.resid), data = m2_test_aug) %>%
  select(n, min, median, max, mean, sd) %>%
  kable(digits = 3)

sqrt(mean(m2_test_aug$.resid^2))
```

Test Set Error Summary | OLS model `m1` | Bayes model `m2`
----: | ----: | -----:
Mean Absolute Prediction Error | `r round_half_up(mean(abs(m1_test_aug$.resid)),3)` | `r round_half_up(mean(abs(m2_test_aug$.resid)),3)`
Maximum Absolute Prediction Error | `r round_half_up(max(abs(m1_test_aug$.resid)),3)` | `r round_half_up(max(abs(m2_test_aug$.resid)),3)`
Root Mean Squared Prediction Error | `r round_half_up(sqrt(mean(m1_test_aug$.resid^2)),3)` | `r round_half_up(sqrt(mean(m2_test_aug$.resid^2)),3)`

# What if we add another predictor? (Insurance)

## Plotting `sbp` vs. `dbp` and `insurance`

```{r, fig.height = 4.5}
ggplot(data = dm_train, aes(x = dbp, y = sbp, 
                col = insurance, group = insurance)) +
  geom_point() + 
  geom_smooth(method = "lm", formula = y ~ x, se = FALSE)
```

## Two possible models

```{r}
m3_train <- lm(sbp ~ dbp + insurance, data = dm_train)
m4_train <- lm(sbp ~ dbp * insurance, data = dm_train)
```

- What is the difference between `m3` and `m4`?
  - Model `m3` will allow the intercept term of the `sbp`-`dbp` relationship to vary depending on insurance.
  - Model `m4` will allow both the slope and intercept of the `sbp`-`dbp` relationship to vary depending on insurance.

## Equation for `m3` (`sbp` ~ `dbp` + `insurance`)

```{r, results = 'asis'}
extract_eq(m3_train, use_coefs = TRUE, 
           wrap = TRUE, terms_per_line = 2)
```

>- Predicted `sbp` by `m3` for a Commercial subject?
>- `sbp` = 77.58 + 0.72*`dbp` + 1.11(1) + 2.73(0) + 1.16(0)
>- `sbp` = 78.69 + 0.72*`dbp`
>- For a Medicaid subject, `m3` predicts `sbp` = 77.58 + 0.72 `dbp`
>- For a Medicare subject, `m3` predicts `sbp` = 80.31 + 0.72 `dbp`
>- For an uninsured subject, `m3` predicts `sbp` = 78.74 + 0.72 `dbp`
>- Note: only the intercept term varies by insurance in `m3`.

## Equation for `m4` (`sbp` ~ `dbp` * `insurance`)

```{r, results = 'asis'}
extract_eq(m4_train, use_coefs = TRUE, 
           wrap = TRUE, terms_per_line = 2)
```

>- `m4` predicts, for a Commercial subject...
>- `sbp` = 60.26 + 0.94 * `dbp` + 23.54 (1) + 31.04 (0) + 25.78 (0) - 0.29 (dbp * 1) - 0.38 (dbp * 0) - 0.32 (dbp * 0)
>- `sbp` = (60.26 + 23.54) + (0.94 - 0.29) * `dbp`
>- `sbp` = 83.80 - 0.65 `dbp` for Commercial subjects

## Equation for `m4` (`sbp` ~ `dbp` * `insurance`)

```{r, results = 'asis'}
extract_eq(m4_train, use_coefs = TRUE, 
           wrap = TRUE, terms_per_line = 2)
```

- For Medicaid subjects, `sbp` = 60.26 + 0.94 * `dbp`
- For Medicare subjects, `sbp` = 91.30 + 0.56 * `dbp`
- For the uninsured, `sbp` = 86.04 + 0.62 * `dbp`
- So both the slope and the intercept are changing in `m4`

## How do these models do in the training sample?

- Model `m3`

```{r}
glance(m3_train) %>% 
  select(r.squared, adj.r.squared, sigma, AIC, BIC) %>% 
  kable(digits = c(3, 3, 1, 1, 1))
```

- Model `m4`

```{r}
glance(m4_train) %>% 
  select(r.squared, adj.r.squared, sigma, AIC, BIC) %>% 
  kable(digits = c(3, 3, 1, 1, 1))
```


## Augmenting and Testing Models `m3` and `m4`

```{r}
m3_train_aug <- augment(m3_train, data = dm_train)
m3_test_aug <- augment(m3_train, newdata = dm_test)

m4_train_aug <- augment(m4_train, data = dm_train)
m4_test_aug <- augment(m4_train, newdata = dm_test)
```

## Residuals (training sample) for `m3_train`

```{r, echo = FALSE, message = FALSE}
p1 <- ggplot(m3_train_aug, aes(sample = .resid)) +
  geom_qq(col = "dodgerblue") + geom_qq_line(col = "black") + 
  theme(aspect.ratio = 1) + 
  labs(title = "Normal Q-Q: 698 m3 Residuals")

p2 <- ggplot(m3_train_aug, aes(x = .resid)) +
  geom_histogram(aes(y = stat(density)), 
                 bins = 20, fill = "dodgerblue", col = "yellow") +
  stat_function(fun = dnorm, 
                args = list(mean = mean(m3_train_aug$.resid), 
                            sd = sd(m3_train_aug$.resid)),
                col = "black", lwd = 1.5) +
  labs(title = "Hist + Normal Density: m3 Residuals")

p3 <- ggplot(m3_train_aug, aes(x = .resid, y = "")) +
  geom_boxplot(fill = "dodgerblue", outlier.color = "dodgerblue") + 
  labs(title = "Boxplot: m3 Residuals", y = "")

p1 + (p2 / p3 + plot_layout(heights = c(4,1)))

mosaic::favstats(~ .resid, data = m3_train_aug) %>% kable(digits = 1)
```

## `m3_train`: Residuals vs. Predicted (Fitted) Values

- We're looking for a "fuzzy football"...

```{r, fig.height = 5, echo = FALSE}
ggplot(m3_train_aug, aes(x = .fitted, y = .resid)) +
  geom_point() +
  geom_smooth(method = "lm", col = "red",
              formula = y ~ x, se = FALSE) + 
  geom_smooth(method = "loess", col = "blue",
              formula = y ~ x, se = FALSE) +
  labs(title = "m3_train: Residuals vs. Fitted Values", 
       x = "Fitted sbp values", y = "Residuals")
```

## Residuals (training sample) for `m4_train`

```{r, echo = FALSE, message = FALSE}
p1 <- ggplot(m4_train_aug, aes(sample = .resid)) +
  geom_qq(col = "seagreen") + geom_qq_line(col = "black") + 
  theme(aspect.ratio = 1) + 
  labs(title = "Normal Q-Q: 698 m4 Residuals")

p2 <- ggplot(m4_train_aug, aes(x = .resid)) +
  geom_histogram(aes(y = stat(density)), 
                 bins = 20, fill = "seagreen", col = "yellow") +
  stat_function(fun = dnorm, 
                args = list(mean = mean(m4_train_aug$.resid), 
                            sd = sd(m4_train_aug$.resid)),
                col = "black", lwd = 1.5) +
  labs(title = "Hist + Normal Density: m4 Residuals")

p3 <- ggplot(m4_train_aug, aes(x = .resid, y = "")) +
  geom_boxplot(fill = "seagreen", outlier.color = "seagreen") + 
  labs(title = "Boxplot: m4 Residuals", y = "")

p1 + (p2 / p3 + plot_layout(heights = c(4,1)))

mosaic::favstats(~ .resid, data = m4_train_aug) %>% kable(digits = 1)
```

## `m4_train`: Residuals vs. Predicted (Fitted) Values

- We're looking for a "fuzzy football"...

```{r, fig.height = 5, echo = FALSE}
ggplot(m4_train_aug, aes(x = .fitted, y = .resid)) +
  geom_point() +
  geom_smooth(method = "lm", col = "red",
              formula = y ~ x, se = FALSE) + 
  geom_smooth(method = "loess", col = "blue",
              formula = y ~ x, se = FALSE) +
  labs(title = "m4_train: Residuals vs. Fitted Values", 
       x = "Fitted sbp values", y = "Residuals")
```


## Comparing performance on the training data

```{r}
bind_rows(glance(m1_train), glance(m2_train),
          glance(m3_train), glance(m4_train)) %>%
  mutate(modname = c("m1", "m2", "m3", "m4")) %>%
  select(modname, r2 = r.squared, adj_r2 = adj.r.squared, 
         sigma, AIC, BIC) %>%
  kable(digits = c(0, 3, 3, 2, 1, 1))
```


- The `glance()` function produces different results for a Bayesian `stan_glm()` model like `m2`, so we'll ignore that for now.

## Comparing performance on the test data

Here are some fundamental summaries of absolute prediction error (APE) along with the root mean squared prediction error (RMSPE) for each of our models, in the **testing** sample.

Summary | Mean APE | Max APE | RMSPE
--------: | --------: | -------: | -------:
`m1_train`: `lm` | `r round_half_up(mean(abs(m1_test_aug$.resid)),3)` | `r round_half_up(max(abs(m1_test_aug$.resid)),3)` | `r round_half_up(sqrt(mean(m1_test_aug$.resid^2)),3)`
`m2_train`: `stan_glm` | `r round_half_up(mean(abs(m2_test_aug$.resid)),3)` | `r round_half_up(max(abs(m2_test_aug$.resid)),3)` | `r round_half_up(sqrt(mean(m2_test_aug$.resid^2)),3)`
`m3_train`: `dbp+insurance` | `r round_half_up(mean(abs(m3_test_aug$.resid)),3)` | `r round_half_up(max(abs(m3_test_aug$.resid)),3)` | `r round_half_up(sqrt(mean(m3_test_aug$.resid^2)),3)`
`m4_train`: `dbp*insurance` | `r round_half_up(mean(abs(m4_test_aug$.resid)),3)` | `r round_half_up(max(abs(m4_test_aug$.resid)),3)` | `r round_half_up(sqrt(mean(m4_test_aug$.resid^2)),3)`

- Which of these models displays the strongest predictive performance in our test sample?

## Reminder of Today's Agenda

1. Ingesting `dm1000` data using R data set format (`.Rds`)
2. Partitioning data into model training/test samples.
3. Augmenting a Scatterplot (labeling, size, color) and fitting a simple OLS (linear) model `m1`
4. Using `summary()` and `extract_eq()` on a regression model.
5. The broom package and `tidy()`, `glance()` and `augment()`
6. Calibrating your understanding of R-square a bit
7. Assessing Regression Assumptions with Residual Plots
8. Making Predictions into the Test Sample
9. Assessing Quality of Fit using the Test Sample with mean and maximum absolute prediction error and with RMSPE
10. Fitting a Bayesian Linear Model with default priors (`m2`)
11. Including Insurance without (`m3`) and with (`m4`) interaction with `dbp` in linear models

## Session Information

```{r}
#| echo: true
sessionInfo()
```
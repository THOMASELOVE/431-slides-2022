---
title: "431 Class 03"
author: "Thomas E. Love, Ph.D."
date: "2022-09-06"
format:
  revealjs: 
    theme: simple
    self-contained: true
    slide-number: true
    preview-links: auto
    logo: 431-class-foot2.png
    footer: "431 Class 03 | 2022-09-06 | https://thomaselove.github.io/431-2022/"
---

## Today's Plan

We're using R Markdown to gather together into a single document:

- the code we build, 
- text commenting on and reacting to that code, and 
- the output of the analyses we build.

Everything in these slides is also going into our R Markdown file.

::: aside
Version `r Sys.time()`
:::

## Load packages and set theme

```{r}
#| echo: true
#| message: false

library(janitor)
library(knitr)
library(tidyverse)

theme_set(theme_bw())
```

Loading packages in R is like opening up apps on your phone. We need to tell R that, in addition to the base functions available in the software, we also have other functions we want to use. 

- Why are we loading these packages, in particular?

## On the tidyverse meta-package {.smaller}

- The most important package is actually a series of packages called the `tidyverse`, which we'll use in every R Markdown file we create this semester. 
    - The `tidyverse` includes several packages, all developed (in part) by Hadley Wickham, Chief Scientist at RStudio.
    - `dplyr` is our main package for data wrangling, cleaning and transformation
    - `ggplot2` is our main visualization package we'll use for visualization
    - other `tidyverse` help import data, work with factors and other common activities.
    
## More on today's packages

- The `janitor` package has some tools for examining, cleaning and tabulating data (including `tabyl()` and `clean_names()`) that we'll use regularly.
- The `knitr` package has a function called `kable()` that we'll sometimes use to neaten up results.
- It's helpful to load the `tidyverse` package last.

## Today's Data

Our data come from the Quick 15-item Survey we did in Class 02 ([pdf in Class 02 README](https://github.com/THOMASELOVE/431-classes-2022/tree/main/class02)), which we've done (in various forms) since 2014. 

- A copy of these data (in .csv format) is on our [431-data page](https://github.com/THOMASELOVE/431-data), and also linked on our [Class 03 README](https://github.com/THOMASELOVE/431-classes-2022/tree/main/class03).

Today, we'll tackle several exploratory questions of interest...

## Today's Questions of Interest

1. What is the distribution of pulse rates among students in 431 since 2014?
2. Does the distribution of student heights change materially over time?
3. Do taller people appear to have paid less for their most recent haircut?
4. Do students have a more substantial tobacco history if they prefer to speak English or a language other than English?

## Read in data from `.csv` file

```{r}
#| echo: true
quicksur_raw <- 
  read_csv("c03/data/quick_survey_2022.csv", show_col_types = FALSE) |>
  clean_names()
```

- Note the `<-` assignment arrow to create `quicksur_raw`
- Here, we use `read_csv` to read in data from the `c03/data` subfolder of my R project directory which contains the `quick_survey_2022.csv` file from our [431-data page](https://github.com/THOMASELOVE/431-data).
- We use `show_col_types = FALSE` to suppress some unnecessary output describing the column types
- We use `clean_names()` from the janitor package
- Note the use of the pipe `|>` to direct the information flow

## What is the result?

```{r}
#| echo: true
quicksur_raw
```

## A more detailed look?

```{r}
#| echo: true
glimpse(quicksur_raw)
```

## Counting Categories

```{r}
#| echo: true
quicksur_raw |> count(glasses)
```

```{r}
#| echo: true
quicksur_raw |> count(glasses, english)
```

## Favorite Color in 2022?

```{r}
#| echo: true
quicksur_raw |>
    filter(year == "2022") |>
    tabyl(favcolor) |>
    adorn_pct_formatting()
```

## Using `summary()` on Quantities

```{r}
#| echo: true
quicksur_raw |> 
  select(love_htcm, haircut, height_in, lastsleep) |>
  summary()
```

- Numerical summaries (five quantiles, plus the mean) for:
  - your guess of my height (in cm), the price of your last haircut, your height (in inches), and the hours of sleep you got last night
- How many observations are available for these measures?

# Manage the data into `qsdat`

## Recall our Questions of Interest

1. What is the distribution of pulse rates among students in 431 since 2014?
2. Does the distribution of student heights change materially over time?
3. Do taller people appear to have paid less for their most recent haircut?
4. Do students have a more substantial tobacco history if they prefer to speak English or a language other than English?

## Variables we'll look at closely today {.smaller}

To address our Questions of Interest, we need these seven variables in our analytic data frame (tibble.)

-   `student`: student identification (numerical code)
-   `year`: indicates year when survey was taken (August)
-   `english`: y = prefers to speak English, else n
-   `smoke`: 1 = never smoker, 2 = quit, 3 = current
-   `pulse`: pulse rate (beats per minute)
-   `height_in`: student's height (in inches)
-   `haircut`: price of student's last haircut (in \$)

## Select our variables

```{r}
#| echo: true
qsdat <- quicksur_raw |>
    select(student, year, english, smoke, 
           pulse, height_in, haircut)
```

- The `select()` function chooses the variables (columns) we want to keep in our new tibble called `qsdat`.
- What should the result of this code look like?

## What do we have now?

```{r}
#| echo: true
qsdat
```

## Initial Numeric Summaries

- Is everything the "type" of variable it should be? 
- Are we getting the summaries we want?

```{r}
#| echo: true
summary(qsdat)
```

## What should we be seeing?

- Categorical variables should list the categories, with associated counts. 
  - To accomplish this, the variable needs to be represented in R with a `factor`, rather than as a `character` or `numeric` variable.
- Quantitative variables should show the minimum, median, mean, maximum, etc.

```{r}
#| echo: true
names(qsdat)
```

## Change categorical variables to factors

We want the `year` and `smoke` information treated as categorical, rather than as quantitative, and the `english` information as a factor, too. Also, do we want to summarize the student ID codes?

- We use the `mutate()` function to help with this.

```{r}
#| echo: true
qsdat <- qsdat |>
    mutate(year = as_factor(year),
           smoke = as_factor(smoke),
           english = as_factor(english),
           student = as.character(student))
```

- Note that it's `as_factor()` but `as.character()`. Sigh.

## Next step: Recheck the summaries and do range checks

-   Do these summaries make sense?
-   Are the minimum and maximum values appropriate?
-   How much missingness are we to deal with?

## Now, how's our summary?

```{r}
#| echo: true

summary(qsdat)
```

- Some things to look for appear on the next slide.

## What to look for...

- Are we getting counts for all variables that are categorical?
    - Do the category levels make sense?
- Are we getting means and medians for all variables that are quantities?
    - Do the minimum and maximum values make sense for each of these quantities?
- Which variables have missing data, as indicated by `NA's`?

## The summary for `year` is an issue

- Just to fill in the gap left by the `summary()` result, how many students responded each year?

```{r}
#| echo: true
qsdat |> tabyl(year) |> adorn_totals() |> adorn_pct_formatting()
```

# Question 1 <br /> (Distribution of Student Pulse Rates)

## Histogram, first try

-   What is the distribution of student `pulse` rates?

```{r}
#| echo: true
#| output-location: column-fragment

ggplot(data = qsdat, 
       aes(x = pulse)) +
    geom_histogram(bins = 30,
      fill = "royalblue", 
      col = "seagreen1")
```

## Describing the Pulse Rates

How might we describe this distribution?

- What is the center?
- How much of a range around that center do we see? How spread out are the data?
- What is the shape of this distribution?
    - Is it symmetric, or is it skewed to the left or to the right? 

(Histogram is replotted on the next slide)

## Histogram, first try again

```{r}
#| echo: true
ggplot(data = qsdat, aes(x = pulse)) +
    geom_histogram(bins = 30, fill = "royalblue", col = "seagreen1")
```

## Fundamental Numerical Summaries

```{r}
#| echo: true
qsdat |> select(pulse) |> summary()
```

- How do the summary statistics help us describe the data?
- Do the values make sense to you?

```{r}
#| echo: true
#| message: false
mosaic::favstats(~ pulse, data = qsdat)
```

## Histogram, version 2

```{r}
#| echo: true
#| output-location: slide

temp <- qsdat |>
  filter(complete.cases(pulse))

ggplot(data = temp, aes(x = pulse)) +
    geom_histogram(fill = "seagreen", col = "white", bins = 20) +
    labs(title = "Pulse Rates of Dr. Love's students",
         subtitle = "2014 - 2022",
         y = "Number of Students",
         x = "Pulse Rate (beats per minute)")
```

- How did we deal with missing data?
- How did we add axis labels and titles to the plot?
- What is the distinction between `fill` and `col`?
- How many bins should we use?

# Question 2 <br /> (Student Heights over Time)

## Yearly Five-Number Summaries

```{r}
#| echo: true
#| eval: false
qsdat |>
    filter(complete.cases(height_in)) |>
    group_by(year) |>
    summarize(n = n(), min = min(height_in), q25 = quantile(height_in, 0.25),
              median = median(height_in), q75 = quantile(height_in, 0.75),
              max = max(height_in))
```

- What should this produce? (Results on next slide)

## Yearly Five-Number Summaries

```{r}
qsdat |>
    filter(complete.cases(height_in)) |>
    group_by(year) |>
    summarize(n = n(), min = min(height_in), q25 = quantile(height_in, 0.25),
              median = median(height_in), q75 = quantile(height_in, 0.75),
              max = max(height_in))
```

- Does the distribution of heights change materially in 2014-2022?
- What are these summaries, specifically?

## Five-Number Summary

- Key summaries based on percentiles / quantiles
    - minimum = 0th, maximum = 100th, median = 50th
    - quartiles (25th, 50th and 75th percentiles)
    - Range is maximum - minimum
    - IQR (inter-quartile range) is 75th - 25th percentile
- These summaries are generally more resistant to outliers than mean, standard deviation
- Form the elements of a boxplot (box-and-whisker plot)

## Comparison Boxplot of Heights by Year

```{r}
#| echo: true
#| output-location: slide

temp2 <- qsdat |>
    filter(complete.cases(height_in)) 

ggplot(data = temp2, aes(x = year, y = height_in)) +
    geom_boxplot() +
    labs(title = "Heights of Dr. Love's students, by year",
         subtitle = "2014 - 2022", x = "Year", y = "Height (in inches)")
```

- How did we deal with missing data here?

## Thinking about the Boxplot

- Box covers the middle half of the data (25th and 75th percentiles), and the solid line indicates the median
- Whiskers extend from the quartiles to the most extreme values that are not judged by **Tukey's** "fences" method to be candidate outliers
    - Fences are drawn at 25th percentile - 1.5 IQR and 75th percentile + 1.5 IQR
- Are any values candidate outliers by this method? For which years?
- Was it important to change `year` to a factor earlier?

## Adding a Violin to the Boxplot

- When we'd like to better understand the shape of a distribution, we can amplify the boxplot.

```{r}
#| echo: true
#| output-location: slide
temp2 <- qsdat |>
    filter(complete.cases(height_in))

ggplot(data = temp2, aes(x = year, y = height_in)) +
    geom_violin() +
    geom_boxplot(aes(fill = year), width = 0.3) +
    guides(fill = "none") +
    scale_fill_viridis_d() +
    labs(title = "Heights of Dr. Love's students, by year",
         subtitle = "2014 - 2022", x = "Year", y = "Height (in inches)")
```

## Thinking About our Boxplot with Violin

- How did we change the boxplot when we added the violin?
- What would happen if we added the boxplot first and the violin second?
- What does `guides(fill = "none")` do?
- What does `scale_fill_viridis_d()` do?

## Table of Means and Standard Deviations

```{r}
#| echo: true

qsdat |>
    filter(complete.cases(height_in)) |>
    group_by(year) |>
    summarize(n = n(), mean = mean(height_in), sd = sd(height_in))
```

## The Empirical Rule for Approximately Normal Distributions {.smaller}

If the data followed a Normal (or Gaussian) distribution, then 

- approximately 68% of heights would be within 1 SD of the mean, 
- approximately 95% of heights would be within 2 SD of the mean, while 
- nearly all (99.7%) would be within 3 SD of the mean.

In 2022, we had 54 students whose `height_in` was available, with mean 68.4 inches (173.7 cm) and standard deviation 3.7 inches (9.4 cm).

What do the histogram (next slide) and boxplot (seen earlier) suggest about whether a Normal model with this mean and standard deviation would hold well for these 54 student heights?

## Histogram of 2022 Student Heights

```{r}
#| echo: true
#| output-location: slide

temp22 <- qsdat |>
  filter(complete.cases(height_in)) |>
  filter(year == "2022")

ggplot(data = temp22, aes(x = height_in)) +
    geom_histogram(fill = "salmon", col = "white", binwidth = 1) +
    labs(title = "Heights of Dr. Love's students",
         subtitle = "2022 (n = 54 students with height data)",
         y = "Number of Students", x = "Height (inches)")
```

- How did we use the two `filter()` statements?
- Why might I have changed from specifying `bins` to `binwidth` here?

## Checking the 1-SD Empirical RUle

- Of the 54 students in 2022 with heights, how many were within 1 SD of the mean?
- How many were in between 68.4 - 3.7 = 64.7 inches and 68.4 + 3.7 = 72.1 inches?

```{r}
#| echo: true

qsdat |> filter(complete.cases(height_in)) |>
    filter(year == "2022") |>
    count(height_in >= 64.7 & height_in <= 72.1)

39/(39+15)
```

## 2-SD Empirical RUle

- How many of the 54 `height_in` values gathered in 2022 were between 68.4 - 2(3.7) = 61.0 and 68.4 + 2(3.7) = 75.8 inches?


```{r}
#| echo: true
qsdat |> filter(complete.cases(height_in)) |>
    filter(year == "2022") |>
    count(height_in >= 61.0 & height_in <= 75.8)

52/(52+2)
```

## 3-SD Empirical RUle

- How many of the 54 `height_in` values gathered in 2022 were between 68.4 - 3(3.7) = 57.3 and 68.4 + 3(3.7) = 79.5 inches?

```{r}
#| echo: true
qsdat |> filter(complete.cases(height_in)) |>
    filter(year == "2022") |>
    count(height_in >= 57.3 & height_in <= 79.5)

54/(54+0)
```


